{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy\n",
    "import copy\n",
    "import tqdm\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(torch.nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(\n",
    "            in_channels=input_channels, out_channels=6, kernel_size=5, stride=1)\n",
    "        self.pool1 = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = torch.nn.Conv2d(\n",
    "            in_channels=6, out_channels=16, kernel_size=5, stride=1)\n",
    "        self.pool2 = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = torch.nn.Linear(in_features=16 * 4 * 4, out_features=120)\n",
    "        self.fc2 = torch.nn.Linear(in_features=120, out_features=84)\n",
    "        self.fc3 = torch.nn.Linear(in_features=84, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(torch.relu(self.conv1(x)))\n",
    "        x = self.pool2(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Loss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        return torch.nn.functional.cross_entropy(input, target)\n",
    "\n",
    "\n",
    "class Server:\n",
    "    def __init__(self, model, client_params):\n",
    "        self.model = copy.deepcopy(model)\n",
    "        self.client_params = client_params\n",
    "        self.n_client = len(self.client_params)\n",
    "        self.parameters = self.client_params[0]\n",
    "\n",
    "        self.fed_avg()\n",
    "        self.model.load_state_dict(self.parameters)\n",
    "\n",
    "    def fed_avg(self):\n",
    "        for client in range(1, self.n_client):\n",
    "            for key in self.parameters:\n",
    "                new_params = self.client_params[client][key]\n",
    "                # print(new_params.equal(self.server_params[key]), end=' | ')\n",
    "                self.parameters[key] = self.parameters[key].add(\n",
    "                    new_params)\n",
    "                # tmp_1 = copy.deepcopy(new_params)\n",
    "                # tmp_2 = copy.deepcopy(self.parameters[key])\n",
    "                # print(new_params.equal(tmp_2.div(2)))\n",
    "        for key in self.parameters:\n",
    "            self.parameters[key] = self.parameters[key].div(2)\n",
    "\n",
    "\n",
    "class DealDataset(Dataset):\n",
    "    def __init__(self, dataset, idx):\n",
    "        self.dataset = dataset\n",
    "        self.idx = idx\n",
    "        self.len = len(idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.dataset[self.idx[index]]\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx_split(dataset, mode='iid', n_dataset=1, n_data_each_set=1):\n",
    "    labels_list = dataset.targets.tolist()\n",
    "    all_labels = set(labels_list)\n",
    "    idx_label = dict()\n",
    "    for label in all_labels:\n",
    "        idx_label[label] = list()\n",
    "        for idx, label_in_list in enumerate(labels_list):\n",
    "            if label_in_list == label:\n",
    "                idx_label[label] += [idx]\n",
    "\n",
    "    if mode == 'iid':\n",
    "        if n_dataset * n_data_each_set > len(dataset):\n",
    "            raise ValueError(\n",
    "                f'number of client ({n_dataset}) times number of data of each client ({n_data_each_set}) no more than number of total data ({len(dataset)})')\n",
    "        n_each_set = dict()\n",
    "        for label in all_labels:\n",
    "            n_each_set[label] = int(\n",
    "                len(idx_label[label]) / len(labels_list) * n_data_each_set)\n",
    "        dataset_splited = dict()\n",
    "        left_idx_label = idx_label\n",
    "        for i in range(n_dataset):\n",
    "            dataset_splited[i] = list()\n",
    "            for label in all_labels:\n",
    "                # print(len(left_idx_label[label]), n_each_set[label])\n",
    "                choiced_idx = numpy.random.choice(\n",
    "                    left_idx_label[label],\n",
    "                    n_each_set[label],\n",
    "                    replace=False)\n",
    "                dataset_splited[i] += list(choiced_idx)\n",
    "                left_idx_label[label] = list(\n",
    "                    set(left_idx_label[label]) - set(dataset_splited[i]))\n",
    "                # print(f'client={i}, label={label}, dataset_splited[i]={len(dataset_splited[i])}')\n",
    "        return dataset_splited\n",
    "    elif mode == 'partial-iid':\n",
    "        print('TO DO.')\n",
    "\n",
    "\n",
    "def train_model(model, dataset, device='cpu', epochs=1, tqdm_position=0):\n",
    "    trained_model = copy.deepcopy(model).to(device)\n",
    "    trained_model.train()\n",
    "    train_dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(trained_model.parameters())\n",
    "    for epoch in range(epochs):\n",
    "        for i, (data, label) in enumerate(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            output = trained_model(data.to(device))\n",
    "            loss = criterion(output, label.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        #     if (i+1) % 100 == 0:\n",
    "        #         print('\\r', end='')\n",
    "        #         print(\n",
    "        #             f'step [{i+1}/{len(train_dataloader)}], loss: {loss.item():.4f}', end='')\n",
    "        # print(f'\\nepoch {epoch+1}/{epochs} down.')\n",
    "    return trained_model\n",
    "\n",
    "\n",
    "def eval_model(model, dataset, device):\n",
    "    server_model = copy.deepcopy(model)\n",
    "    server_model.eval()\n",
    "    server_model.to(device)\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "        for images, labels in data_loader:\n",
    "            outputs = server_model(images.to(device))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.to(device)).sum().item()\n",
    "        print('Test Accuracy: {:.2f}%'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "communication_round:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "communication_round: 100%|██████████| 5/5 [00:13<00:00,  2.77s/it]\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(device)\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "n_total_client = 5\n",
    "n_data = 12000\n",
    "communication_round = 5\n",
    "epochs = 1\n",
    "n_client = 2\n",
    "\n",
    "model = LeNet5(input_channels=1)\n",
    "idx_splited = idx_split(dataset=train_dataset,\n",
    "                        n_dataset=n_total_client,\n",
    "                        n_data_each_set=n_data)\n",
    "# print(len(idx_splited), len(idx_splited[0]))\n",
    "dataset_client = dict()\n",
    "for i in range(n_total_client):\n",
    "    dataset_client[i] = DealDataset(train_dataset, idx_splited[i])\n",
    "\n",
    "server_model = copy.deepcopy(model)\n",
    "tqdm_position = 0\n",
    "for i in tqdm.tqdm(range(communication_round),\n",
    "                   desc='communication_round',\n",
    "                   position=tqdm_position):\n",
    "    client = dict()\n",
    "    client_param = dict()\n",
    "    choicen_client = numpy.random.choice(\n",
    "        range(n_total_client), n_client, replace=False)\n",
    "    for j, k in enumerate(choicen_client):\n",
    "        client[j] = train_model(\n",
    "            model=server_model,\n",
    "            dataset=dataset_client[k],\n",
    "            device=device,\n",
    "            epochs=epochs,\n",
    "            tqdm_position=tqdm_position+1)\n",
    "        client_param[j] = client[j].state_dict()\n",
    "    server_model = Server(model=model, client_params=client_param).model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.11%\n",
      "Test Accuracy: 97.50%\n",
      "Test Accuracy: 97.87%\n"
     ]
    }
   ],
   "source": [
    "eval_model(client[0], test_dataset, device)\n",
    "eval_model(client[1], test_dataset, device)\n",
    "eval_model(server_model, test_dataset, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "federated_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
