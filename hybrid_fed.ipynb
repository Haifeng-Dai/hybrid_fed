{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[H\u001b[2Jcuda\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "%clear\n",
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.model_util import LeNet5, CNN\n",
    "from utils.data_util import *\n",
    "from utils.lib_util import *\n",
    "from utils.train_util import *\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "torch.set_printoptions(precision=2,\n",
    "                       threshold=1000,\n",
    "                       edgeitems=5,\n",
    "                       linewidth=1000,\n",
    "                       sci_mode=False)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file existed.\n"
     ]
    }
   ],
   "source": [
    "save_path = './data/dealed-data/'\n",
    "\n",
    "dataset = 'mnist'\n",
    "file_path = save_path + dataset + '_train_dataset_splited.pt'\n",
    "if os.path.exists(file_path):\n",
    "    [train_dataset_splited, test_dataset_o] = torch.load(file_path)\n",
    "    print('file existed.')\n",
    "else:\n",
    "    if not os.path.exists(save_path):\n",
    "        os.mkdir(save_path)\n",
    "    train_dataset_o, test_dataset_o = get_dataset(dataset)\n",
    "    train_dataset_splited = split_data(train_dataset_o)\n",
    "    torch.save([train_dataset_splited, test_dataset_o], file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.8\n",
    "beta = 0.2\n",
    "\n",
    "num_all_client = 6\n",
    "num_all_server = 2\n",
    "all_client = [i for i in range(num_all_client)]\n",
    "all_server = [i for i in range(num_all_server)]\n",
    "num_server_commu = 3\n",
    "num_client_commu = 3\n",
    "num_client_train = 3\n",
    "\n",
    "server_client_1 = [0, 1, 2]\n",
    "server_client_2 = [3, 4, 5]\n",
    "server_client = [server_client_1, server_client_2]\n",
    "neighbor_server = [1, 0]\n",
    "\n",
    "idx_client_target = train_data_split(train_dataset_splited, all_client)\n",
    "all_target = train_dataset_splited.keys()\n",
    "\n",
    "public_idx, test_idx = split_idx_proportion([i for i in range(len(test_dataset_o))], [0.2, 0.8])\n",
    "public_dataset = [test_dataset_o[idx] for idx in public_idx]\n",
    "test_dataset = [test_dataset_o[idx] for idx in test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_client = get_list(num_all_client)\n",
    "# for client in all_client:\n",
    "#     train_dataset_client.append([])\n",
    "for client in all_client:\n",
    "    for target in all_target:\n",
    "        # train_dataset_client_new = idx_to_dataset(train_dataset_splited[target], idx_client_target[client][target])\n",
    "        train_dataset_client_new = [train_dataset_splited[target][idx] for idx in idx_client_target[client][target]]\n",
    "        train_dataset_client[client].extend(train_dataset_client_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_model = LeNet5(28, 28, 1, 10)\n",
    "\n",
    "client_model = get_list(num_all_client, initial_model)\n",
    "# for client in all_client:\n",
    "#     client_model.append(initial_model)\n",
    "\n",
    "model_server = get_list(num_all_server)\n",
    "# for server in all_server:\n",
    "#     model_server.append(initial_model)\n",
    "logits_server_public = get_list(num_all_server)\n",
    "# for server in all_server:\n",
    "#     logits_server_public.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "kl_div(): argument 'target' (position 2) must be Tensor, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 12\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch_server_commu \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      6\u001b[0m         client_model[client] \u001b[38;5;241m=\u001b[39m train_model(\n\u001b[1;32m      7\u001b[0m             model\u001b[38;5;241m=\u001b[39mclient_model[client],\n\u001b[1;32m      8\u001b[0m             dataset\u001b[38;5;241m=\u001b[39mtrain_dataset_client[client],\n\u001b[1;32m      9\u001b[0m             criterion\u001b[38;5;241m=\u001b[39mLossWithoutDistillation(),\n\u001b[1;32m     10\u001b[0m             device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m     11\u001b[0m             epochs\u001b[38;5;241m=\u001b[39mnum_client_train)\n\u001b[0;32m---> 12\u001b[0m     client_model[client] \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_model\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset_client\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLossWithDistillation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogits_server_public\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_client_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m server \u001b[38;5;129;01min\u001b[39;00m all_server:\n\u001b[1;32m     20\u001b[0m     server_client_model \u001b[38;5;241m=\u001b[39m [client_model[client]\n\u001b[1;32m     21\u001b[0m                            \u001b[38;5;28;01mfor\u001b[39;00m client \u001b[38;5;129;01min\u001b[39;00m server_client[server]]\n",
      "File \u001b[0;32m~/git_res/hybrid_fed/utils/train_util.py:88\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dataset, criterion, device, epochs)\u001b[0m\n\u001b[1;32m     86\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     87\u001b[0m output \u001b[38;5;241m=\u001b[39m trained_model(data\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[0;32m---> 88\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     90\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/app/miniconda3/envs/fl/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/app/miniconda3/envs/fl/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/git_res/hybrid_fed/utils/train_util.py:28\u001b[0m, in \u001b[0;36mLossWithDistillation.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m     25\u001b[0m ce_loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m     26\u001b[0m kl_loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mKLDivLoss(reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatchmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     27\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha \u001b[38;5;241m*\u001b[39m \\\n\u001b[0;32m---> 28\u001b[0m     ce_loss(\u001b[38;5;28minput\u001b[39m, target) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta \u001b[38;5;241m*\u001b[39m \u001b[43mkl_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss\n",
      "File \u001b[0;32m~/app/miniconda3/envs/fl/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/app/miniconda3/envs/fl/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/app/miniconda3/envs/fl/lib/python3.11/site-packages/torch/nn/modules/loss.py:470\u001b[0m, in \u001b[0;36mKLDivLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkl_div\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_target\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/app/miniconda3/envs/fl/lib/python3.11/site-packages/torch/nn/functional.py:2955\u001b[0m, in \u001b[0;36mkl_div\u001b[0;34m(input, target, size_average, reduce, reduction, log_target)\u001b[0m\n\u001b[1;32m   2952\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2953\u001b[0m         reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[0;32m-> 2955\u001b[0m reduced \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkl_div\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_target\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduction \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatchmean\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2958\u001b[0m     reduced \u001b[38;5;241m=\u001b[39m reduced \u001b[38;5;241m/\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: kl_div(): argument 'target' (position 2) must be Tensor, not list"
     ]
    }
   ],
   "source": [
    "for epoch_server_commu in range(num_server_commu):\n",
    "    for epoch_client_commu in range(num_client_commu):\n",
    "        # 边缘服务器协调其客户端进行联邦学习\n",
    "        for server in all_server:\n",
    "            for client in server_client[server]:\n",
    "                client_model[client] = train_model(\n",
    "                    model=client_model[client],\n",
    "                    dataset=train_dataset_client[client],\n",
    "                    criterion=LWoD(),\n",
    "                    device=device,\n",
    "                    epochs=num_client_train)\n",
    "                if epoch_server_commu != 0:\n",
    "                    neighbor_server_model = [client_model[client] for client in server_client[neighbor_server[server]]]\n",
    "                    weight = get_list()\n",
    "                    client_model[client] = train_model_disti(\n",
    "                        model=client_model[client],\n",
    "                        neighbor_server_model = neighbor_server_model,\n",
    "                        weight= ,\n",
    "                        dataset=public_dataset,\n",
    "                        criterion=LWD(alpha, beta, logits_server_public),\n",
    "                        device=device,\n",
    "                        epochs=num_client_train)\n",
    "            for server in all_server:\n",
    "                server_client_model = [client_model[client]\n",
    "                                    for client in server_client[server]]\n",
    "                model_server[server] = EdgeServer(client_model).average()\n",
    "                break\n",
    "            break\n",
    "    # for server in all_server:\n",
    "    #     public_dataloader = DataLoader(\n",
    "    #         dataset=public_dataset,\n",
    "    #         batch_size=1,\n",
    "    #         shuffle=False)\n",
    "    #     model_server_distillation = deepcopy(\n",
    "    #         model_server[server]).eval().to(device)\n",
    "    #     for data, _ in public_dataloader:\n",
    "    #         logits_server_public[server].append(\n",
    "    #             model_server_distillation(data.to(device)))\n",
    "    #         # logits_server_public[server].append(model_server_distillation(data.to(device))[0])\n",
    "        break\n",
    "    break\n",
    "\n",
    "    # edge_server_communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_model = deepcopy(model_server[server]).eval().to(device)\n",
    "# eval_model(the_model, test_dataset, device)\n",
    "test_dataloader = DataLoader(test_dataset, 1)\n",
    "for data, _ in test_dataloader:\n",
    "    output = the_model(data.to(device))\n",
    "    print(output.size())\n",
    "    print(output[0].tolist())\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "federated_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
