{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from utils.model_util import LeNet5, CNN, MLP\n",
    "from utils.train_util import *\n",
    "\n",
    "model = LeNet5(28, 28, 1, 10).cuda()\n",
    "train_dataset_loader = DataLoader(\n",
    "    dataset=torchvision.datasets.MNIST(\n",
    "        root='../data/raw-data/',\n",
    "        train=True,\n",
    "        transform=torchvision.transforms.ToTensor()),\n",
    "    batch_size=600,\n",
    "    shuffle=False)\n",
    "test_dataset_loader = DataLoader(\n",
    "    dataset=torchvision.datasets.mnist.MNIST(\n",
    "        root='../data/raw-data/',\n",
    "        transform=torchvision.transforms.ToTensor()),\n",
    "    batch_size=32,\n",
    "    shuffle=False)\n",
    "test_dataset = torchvision.datasets.mnist.MNIST(\n",
    "    root='../data/raw-data/',\n",
    "    transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "opti = torch.optim.Adam(model.parameters())\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "for data, target in train_dataset_loader:\n",
    "    opti.zero_grad()\n",
    "    output = model(data.cuda())\n",
    "    loss = criterion(output, target.cuda())\n",
    "    loss.backward()\n",
    "    print(loss.item())\n",
    "    opti.step()\n",
    "\n",
    "print(loss, type(loss))\n",
    "print(loss.item(), type(loss.item()))\n",
    "\n",
    "model = LeNet5(28, 28, 1, 10).cuda()\n",
    "train_dataset_loader = DataLoader(\n",
    "    dataset=torchvision.datasets.MNIST(\n",
    "        root='../data/raw-data/',\n",
    "        train=True,\n",
    "        transform=torchvision.transforms.ToTensor()),\n",
    "    batch_size=600,\n",
    "    shuffle=False)\n",
    "test_dataset_loader = DataLoader(\n",
    "    dataset=torchvision.datasets.mnist.MNIST(\n",
    "        root='../data/raw-data/',\n",
    "        transform=torchvision.transforms.ToTensor()),\n",
    "    batch_size=32,\n",
    "    shuffle=False)\n",
    "\n",
    "opti = torch.optim.Adam(model.parameters())\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "loss_sum = 0\n",
    "for data, target in train_dataset_loader:\n",
    "    opti.zero_grad()\n",
    "    output = model(data.cuda())\n",
    "    loss = criterion(output, target.cuda())\n",
    "    # print(f'loss_sum = {loss_sum:<20}', end=' | ')\n",
    "    loss.backward()\n",
    "    loss_sum += loss.item()\n",
    "    # print(f'loss = {loss.item():<20}')\n",
    "    opti.step()\n",
    "\n",
    "def eval_model(model, dataset, device):\n",
    "    '''\n",
    "    评估模型\n",
    "    '''\n",
    "    model_copy = deepcopy(model).eval()\n",
    "    correct = 0\n",
    "    data_loader = DataLoader(dataset, batch_size=32)\n",
    "    for images, targets in data_loader:\n",
    "        outputs = model_copy(images.to(device))\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += torch.eq(predicted, targets.to(device)).sum()\n",
    "    # print(f'Test Accuracy: {100 * correct / total:.2f}%')\n",
    "    accuracy = correct / len(dataset)\n",
    "    return accuracy\n",
    "\n",
    "eval_model(model, test_dataset, 'cuda')\n",
    "\n",
    "model_copy = deepcopy(model).eval()\n",
    "model_copy.eval()\n",
    "model_copy.cuda()\n",
    "correct = 0\n",
    "total = 0\n",
    "data_loader = test_dataset_loader\n",
    "for images, targets in data_loader:\n",
    "    outputs = model_copy(images.cuda())\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += targets.size(0)\n",
    "    correct += (predicted == targets.cuda()).sum().item()\n",
    "    break\n",
    "print('Test Accuracy: {:.2f}%'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8, 13):\n",
    "    print(f'{i:<10}|')\n",
    "    print(f'{i:.2f}|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list(len_list, term=[]):\n",
    "    '''\n",
    "    返回一个全是空列表的列表\n",
    "    '''\n",
    "    list_return = []\n",
    "    for _ in range(len_list):\n",
    "        list_return.append(term)\n",
    "    return list_return\n",
    "\n",
    "num_all_client = 6\n",
    "num_all_server = 2\n",
    "\n",
    "server_model = get_list(num_all_server)\n",
    "server_accuracy = get_list(num_all_server)\n",
    "client_accuracy = get_list(num_all_client)\n",
    "server_client_model = get_list(num_all_server)\n",
    "server_model_distillation_accuracy = get_list(num_all_server)\n",
    "\n",
    "print(client_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.data_util import *\n",
    "from utils.train_util import *\n",
    "from utils.model_util import *\n",
    "from utils.lib_util import *\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(device)\n",
    "\n",
    "save_path = '../data/dealed-data/'\n",
    "train_dataset_o, test_dataset_o = get_dataset(dataset='cifar10')\n",
    "train_dataset_splited = split_data(train_dataset_o)\n",
    "idx_client_target = train_data_split(train_dataset_splited, range(3))\n",
    "all_target = train_dataset_splited.keys()\n",
    "\n",
    "train_dataset_client = list_same_term(3)\n",
    "for client in range(3):\n",
    "    for target in all_target:\n",
    "        train_dataset_client_new = [train_dataset_splited[target][idx]\n",
    "                                    for idx in idx_client_target[client][target]]\n",
    "        train_dataset_client[client].extend(train_dataset_client_new)\n",
    "\n",
    "public_idx, test_idx = split_idx_proportion(\n",
    "    number_list(len(test_dataset_o)), [0.2, 0.8])\n",
    "public_dataset = DealDataset(test_dataset_o, public_idx)\n",
    "test_dataset = DealDataset(test_dataset_o, test_idx)\n",
    "\n",
    "model = CNN(32, 32, 3, 10)\n",
    "trained_model1, _ = train_model(\n",
    "    model=model,\n",
    "    dataset=train_dataset_client[0],\n",
    "    device=device,\n",
    "    epochs=10)\n",
    "print('mode 1: ', eval_model(trained_model1, test_dataset, device))\n",
    "trained_model2, _ = train_model(\n",
    "    model=model,\n",
    "    dataset=train_dataset_client[1],\n",
    "    device=device,\n",
    "    epochs=10)\n",
    "print('mode 2: ', eval_model(trained_model2, test_dataset, device))\n",
    "\n",
    "trained_model3, _ = train_model(\n",
    "    model=model,\n",
    "    dataset=train_dataset_client[2],\n",
    "    device=device,\n",
    "    epochs=10)\n",
    "print('mode 3 before distill: ', eval_model(trained_model3, test_dataset, device))\n",
    "\n",
    "trained_model4, _ = train_model(\n",
    "    model=trained_model3,\n",
    "    dataset=public_dataset,\n",
    "    device=device,\n",
    "    epochs=10)\n",
    "print('mode 3 after distill: ', eval_model(trained_model4, test_dataset, device))\n",
    "\n",
    "trained_model5, _ = train_model_disti(\n",
    "    model=trained_model3,\n",
    "    neighbor_server_model=[trained_model1, trained_model2],\n",
    "    weight=torch.tensor([0.5, 0.5]),\n",
    "    dataset=public_dataset,\n",
    "    alpha=0.5,\n",
    "    device=device,\n",
    "    epochs=10)\n",
    "print('mode 3 train only in public dataset: ', eval_model(trained_model5, test_dataset, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.data_util import *\n",
    "from utils.train_util import *\n",
    "from utils.model_util import *\n",
    "from utils.lib_util import *\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(device)\n",
    "\n",
    "save_path = '../data/dealed-data/'\n",
    "train_dataset_o, test_dataset_o = get_dataset(dataset='cifar100')\n",
    "print(type(train_dataset_o.targets), len(train_dataset_o.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.data_util import *\n",
    "from utils.train_util import *\n",
    "from utils.model_util import *\n",
    "from utils.lib_util import *\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(device)\n",
    "\n",
    "save_path = '../data/dealed-data/'\n",
    "train_dataset_o, test_dataset_o = get_dataset()\n",
    "print(type(train_dataset_o.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand(3, 4)\n",
    "b = a.to('cuda')\n",
    "\n",
    "print(b)\n",
    "print(b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, copy\n",
    "\n",
    "a = [i for i in range(10)]\n",
    "b = [i+100 for i in range(10)]\n",
    "c = {'a': a, 'b': b}\n",
    "\n",
    "d = copy.deepcopy(c['a'])\n",
    "random.shuffle(d)\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [i for i in range(10)]\n",
    "b = a[1:3]\n",
    "c = a[1:]\n",
    "print(a, b, c)\n",
    "a.append(['k'])\n",
    "print(a)\n",
    "a.extend(['k'])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "a = [i for i in range(10)]\n",
    "b = numpy.random.choice(a, 3, replace=True).tolist()\n",
    "print(b, type(b))\n",
    "\n",
    "for i, c in enumerate(b):\n",
    "    print(i)\n",
    "    print(c, type(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('./utils/')\n",
    "\n",
    "from utils.data_util import *\n",
    "\n",
    "_, data, _, _, _ = get_dataset()\n",
    "DataSplit = SplitData(dataset=data)\n",
    "# splited_data = DataSplit.split_data()\n",
    "client_data = DataSplit.part_target(2, 3, [[0, 1], [2, 3], [4, 5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (data, target) in enumerate(client_data[0]):\n",
    "    for j, (data_, target_) in enumerate(client_data[1]):\n",
    "        b = 0\n",
    "        if target_ == target:\n",
    "            a = torch.eq(data_, data)\n",
    "            for i in a[0]:\n",
    "                if False in i:\n",
    "                    b += 1\n",
    "            if b:\n",
    "                continue\n",
    "            else:\n",
    "                print('same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "\n",
    "from utils.model_util import LeNet5\n",
    "from utils.data_util import *\n",
    "from utils.train_util import *\n",
    "\n",
    "device='cuda'\n",
    "\n",
    "train_dataset, test_dataset, c, h, w = get_dataset()\n",
    "num_target = len(set(test_dataset.targets.tolist()))\n",
    "\n",
    "model1 = LeNet5(h, w, c, num_target)\n",
    "model2 = LeNet5(h, w, c, num_target)\n",
    "\n",
    "DataSplited = SplitData(train_dataset)\n",
    "splited_dataset = DataSplited.all_iid(5, 1000)\n",
    "model1_trained = train_model(\n",
    "    model=model1,\n",
    "    dataset=splited_dataset[0],\n",
    "    device=device)\n",
    "model2_disti = train_model_disti(\n",
    "    model=model2,\n",
    "    dataset=splited_dataset[1],\n",
    "    neighbor_server_model=[model1],\n",
    "    weight=torch.tensor([1]),\n",
    "    alpha=0.5,\n",
    "    device=device)\n",
    "\n",
    "eval_model1 = eval_model(\n",
    "    model=model1,\n",
    "    dataset=test_dataset,\n",
    "    device=device)\n",
    "print(eval_model1)\n",
    "eval_model2 = eval_model(\n",
    "    model=model2,\n",
    "    dataset=test_dataset,\n",
    "    device=device)\n",
    "print(eval_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.mps:\n",
    "    print(torch.mps)\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.mps)\n",
    "mps_device = torch.device(\"mps\")\n",
    "print(mps_device, type(mps_device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.backends.cuda.is_built():\n",
    "    print('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand(3, 4)\n",
    "print(a)\n",
    "print(a.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = [i for i in range(10)]\n",
    "y = torch.rand(4, 10)\n",
    "line_list = []\n",
    "for i in range(4):\n",
    "    line_list.append(plt.plot(x, y[i, :]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "sys.path.append('..')\n",
    "from utils.model_util import LeNet5\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils.data_util import get_dataset\n",
    "from utils.train_util import train_model, eval_model\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "            root='../data/raw-data',\n",
    "            train=True,\n",
    "            transform=torchvision.transforms.ToTensor(),\n",
    "            download=True)\n",
    "\n",
    "model = LeNet5(28, 28, 1, 10)\n",
    "train_model(model=model, dataset=train_dataset, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "b = [a, a, a, a]\n",
    "print(b)\n",
    "\n",
    "b[0] = 2\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in range(5):\n",
    "    c = 1\n",
    "    a.append(c)\n",
    "print(id(a[0]), id(a[1]))\n",
    "a[0] += 2\n",
    "print(id(a[0]), id(a[1]))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "b = 0\n",
    "print(id(a), id(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def empty_list(len_list, term=[]):\n",
    "    '''\n",
    "    返回一个全是空列表的列表\n",
    "    '''\n",
    "    list_return = []\n",
    "    for _ in range(len_list):\n",
    "        list_return.append(deepcopy(term))\n",
    "    return list_return\n",
    "\n",
    "a = empty_list(3)\n",
    "b = empty_list(3)\n",
    "print(id(a), id(b))\n",
    "print(id(a[0]), id(b[0]))\n",
    "print(id(a[0]), id(a[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "a = A()\n",
    "b = A()\n",
    "print(id(a), id(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_util import *\n",
    "\n",
    "_, dataset, _, _, _ = get_dataset()\n",
    "print(len(dataset))\n",
    "print(type(dataset[3]), type(dataset[3][1]))\n",
    "# for i, data in enumerate(dataset):\n",
    "#     print(type(i), type(dataset[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_util import *\n",
    "\n",
    "_, dataset, _, _, _ = get_dataset()\n",
    "\n",
    "client_data =split_parts_random(dataset, [2, 3, 4])\n",
    "print(len(client_data), len(client_data[0]), len(client_data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.lib_util import get_logger\n",
    "\n",
    "massage = 'test'\n",
    "file_name = 'test.txt'\n",
    "\n",
    "logger = get_logger(file_name)\n",
    "logger.info(massage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "x = [i for i in range(100)]\n",
    "y = [random.random() for i in range(100)]\n",
    "\n",
    "plt.plot(x, y)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "aa = int(np.log2(8 - 1)) + 1\n",
    "rota = [i for i in range(int(np.log2(8 - 1)) + 1)]\n",
    "\n",
    "source = (2 - rota[2 % len(rota)]) % 8\n",
    "dest = (2 + rota[2 % len(rota)]) % 8\n",
    "\n",
    "print(aa, a, source, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intra_comm_bcast.py\n",
    "\n",
    "import numpy as np\n",
    "from mpi4py import MPI\n",
    "\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "# broadcast a generic object by using bcast\n",
    "if rank == 1:\n",
    "    obj = {'a': 1}\n",
    "else:\n",
    "    obj = None\n",
    "\n",
    "obj = comm.bcast(obj, root=1)\n",
    "print('rank %d has %s' % (rank, obj))\n",
    "\n",
    "# broadcast a numpy array by using Bcast\n",
    "if rank == 2:\n",
    "    ary = np.arange(10, dtype='i')\n",
    "else:\n",
    "    ary = np.empty(10, dtype='i')\n",
    "\n",
    "comm.Bcast(ary, root=2)\n",
    "print('rank %d has %s' % (rank, ary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#下面这个引用就是上面文章提供的脚本mnist.py\n",
    "from mnist import load_mnist\n",
    "from PIL import Image\n",
    "\n",
    "def img_show(img):\n",
    "    pil_img = Image.fromarray(np.uint8(img))\n",
    "    pil_img.show()\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True,\n",
    "normalize=False)\n",
    "img = x_train[0]\n",
    "label = t_train[0]\n",
    "print(label) # 5\n",
    "\n",
    "#这里是把二维图像铺平成一维存放了\n",
    "print(img.shape)          # (784,1)\n",
    "img = img.reshape(28, 28) # 还原为二维\n",
    "print(img.shape)          # (28, 28)\n",
    "\n",
    "img_show(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "data_tf = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "batch_size = 32\n",
    "# 读取测试数据，train=True读取训练数据；train=False读取测试数据\n",
    "train_dataset = datasets.MNIST(root='./data/raw-data/', train=True, transform=data_tf, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data/raw-data/', train=False, transform=data_tf)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "examples = enumerate(test_loader) #img&label\n",
    "batch_idx, (imgs, labels) = next(examples) #读取数据,batch_idx从0开始\n",
    "\n",
    "# print(labels) #读取标签数据\n",
    "# print(labels.shape) #torch.Size([32])，因为batch_size为32\n",
    "\n",
    "#-------------------------------数据显示--------------------------------------------\n",
    "#显示6张图片\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(imgs[i][0], cmap='gray', interpolation='none')#子显示\n",
    "  plt.title(\"Ground Truth: {}\".format(labels[i])) #显示title\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.model_util import *\n",
    "from utils.train_util import *\n",
    "from utils.data_util import *\n",
    "\n",
    "torch.set_printoptions(\n",
    "    precision=2,\n",
    "    threshold=1000,\n",
    "    edgeitems=5,\n",
    "    linewidth=1000,\n",
    "    sci_mode=False)\n",
    "\n",
    "\n",
    "\n",
    "def data_loader(dataset, batch_size, shuffle=True, device='cuda'):  #\n",
    "    num_data = len(dataset)\n",
    "    data_idxs = [i for i in range(num_data)]\n",
    "    if shuffle:\n",
    "        random.shuffle(data_idxs)\n",
    "    num_dataloader = num_data // batch_size\n",
    "    if num_data % batch_size:\n",
    "        num_dataloader += 1\n",
    "\n",
    "    for i in range(num_dataloader):\n",
    "        idx = i * batch_size\n",
    "        if i == num_dataloader-1 and idx < num_data:\n",
    "            image = ()\n",
    "            target = ()\n",
    "            for idx_single in range(idx, num_data):\n",
    "                data = dataset[data_idxs[idx_single]]\n",
    "                image += (data[0],)\n",
    "                target += (data[1],)\n",
    "            data_return = (torch.stack(image).to(device),\n",
    "                           torch.tensor(target).to(device))\n",
    "            yield data_return\n",
    "        else:\n",
    "            image = ()\n",
    "            target = ()\n",
    "            for idx_single in range(idx, idx+batch_size):\n",
    "                data = dataset[data_idxs[idx_single]]\n",
    "                image += (data[0],)\n",
    "                target += (data[1],)\n",
    "            data_return = (torch.stack(image).to(device),\n",
    "                           torch.tensor(target).to(device))\n",
    "            yield data_return\n",
    "\n",
    "\n",
    "def dataloader_(dataset, batch_size, shuffle=True, device='cpu'):\n",
    "    num_data = len(dataset)\n",
    "    images = dataset.data.unsqueeze(1) / 255\n",
    "    target = dataset.targets\n",
    "    idxs = [i for i in range(num_data)]\n",
    "    if shuffle:\n",
    "        random.shuffle(idxs)\n",
    "    num_dataloader = num_data // batch_size\n",
    "    if num_data % batch_size:\n",
    "        num_dataloader += 1\n",
    "    for i in range(num_dataloader):\n",
    "        idx = i * batch_size\n",
    "        if i == num_dataloader-1 and idx < num_data:\n",
    "            data_return = images[idx:]\n",
    "            target_return = target[idx:]\n",
    "            yield (data_return.to(device), target_return.to(device))\n",
    "        else:\n",
    "            data_return = images[idx: idx+batch_size]\n",
    "            target_return = target[idx: idx+batch_size]\n",
    "            yield (data_return.to(device), target_return.to(device))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 一次性将所有内容放到GPU上\n",
    "    train_data, test_data, c, h, w = get_dataset()\n",
    "\n",
    "    # train_data_loader = data_loader(train_data, 10000, shuffle=False)\n",
    "    train_data_loader = dataloader_(train_data, 10000, shuffle=False)\n",
    "    # train_data_loader  =DataLoader(train_data, batch_size=10000, shuffle=False)\n",
    "    for images, targets in train_data_loader:\n",
    "        # print(images[0][0].shape, images[0][0].device)\n",
    "        plt.tight_layout\n",
    "        plt.imshow(images[0][0], cmap='gray', interpolation='none')\n",
    "        # plt.title(\"Ground Truth: {}\".format(targets[0]))\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.show()\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "torch.Size([3, 32, 32]) 6 [[[[0.247 ]]\n",
      "\n",
      "  [[0.2435]]\n",
      "\n",
      "  [[0.2616]]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from utils.data_util import get_dataset\n",
    "\n",
    "train_data, test_data, c, h, w = get_dataset('cifar10')\n",
    "\n",
    "image, target = train_data[0][0], train_data[0][1]\n",
    "CIFAR10_TRAIN_STD = np.array((0.2470, 0.2435, 0.2616))[None, :, None, None]\n",
    "print(image.shape, target, CIFAR10_TRAIN_STD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-1., -1., -1., -1., -1.],\n",
      "          [-1., -1., -1., -1., -1.],\n",
      "          [-1., -1., -1., -1., -1.],\n",
      "          [-1., -1., -1., -1., -1.],\n",
      "          [-1., -1., -1., -1., -1.]],\n",
      "\n",
      "         [[-2., -2., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2.]],\n",
      "\n",
      "         [[-3., -3., -3., -3., -3.],\n",
      "          [-3., -3., -3., -3., -3.],\n",
      "          [-3., -3., -3., -3., -3.],\n",
      "          [-3., -3., -3., -3., -3.],\n",
      "          [-3., -3., -3., -3., -3.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1., -1., -1., -1.],\n",
      "          [-1., -1., -1., -1., -1.],\n",
      "          [-1., -1., -1., -1., -1.],\n",
      "          [-1., -1., -1., -1., -1.],\n",
      "          [-1., -1., -1., -1., -1.]],\n",
      "\n",
      "         [[-2., -2., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2.]],\n",
      "\n",
      "         [[-3., -3., -3., -3., -3.],\n",
      "          [-3., -3., -3., -3., -3.],\n",
      "          [-3., -3., -3., -3., -3.],\n",
      "          [-3., -3., -3., -3., -3.],\n",
      "          [-3., -3., -3., -3., -3.]]]]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "a = torch.ones([2, 3, 5, 5])\n",
    "# print(a)\n",
    "b = np.array((2, 3, 4), dtype='float32')[None, :, None, None]\n",
    "c = a - b\n",
    "print(c, c.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1, 1]) torch.Size([1, 3, 1, 1])\n",
      "tensor([[[[True]],\n",
      "\n",
      "         [[True]],\n",
      "\n",
      "         [[True]]]])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39meq(b1, b2))\n\u001b[1;32m     11\u001b[0m c \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m---> 12\u001b[0m \u001b[43mc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m b\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(c, c\u001b[38;5;241m.\u001b[39mdtype)\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "a = torch.ones([2, 3, 5, 5])\n",
    "# print(a)\n",
    "b = torch.tensor((2, 3, 4), dtype=torch.float32)\n",
    "b1 = b[None, :, None, None]\n",
    "b2 = b.unsqueeze(1).unsqueeze(1).unsqueeze(0)\n",
    "print(b1.shape, b2.shape)\n",
    "print(torch.eq(b1, b2))\n",
    "# c = torch.tensor([1, 1, 1, 1])\n",
    "# c[0, :, 0, 0] = b\n",
    "# print(c, c.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "torch.Size([3, 32, 32]) 3 32 32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from utils.data_util import get_dataset\n",
    "\n",
    "train_data, test_data, c, h, w = get_dataset('cifar10')\n",
    "image, _ = train_data[0]\n",
    "\n",
    "print(image.shape, c, h, w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
