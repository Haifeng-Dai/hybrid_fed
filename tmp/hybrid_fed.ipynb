{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-28 14:33:28] [INFO] device cuda is used.\n",
      "[2023-12-28 14:33:28] [INFO] device cuda is used.\n",
      "[2023-12-28 14:33:28] [INFO] cudnn is actived.\n",
      "[2023-12-28 14:33:28] [INFO] cudnn is actived.\n"
     ]
    }
   ],
   "source": [
    "# %% intial\n",
    "import torch\n",
    "import numpy\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.model_util import *\n",
    "from utils.data_util import *\n",
    "from utils.lib_util import *\n",
    "from utils.train_util import *\n",
    "\n",
    "t = time.localtime()\n",
    "log_path = f'./log/{t.tm_year}-{t.tm_mon}-{t.tm_mday}-{t.tm_hour}-{t.tm_min}.log'\n",
    "log = get_logger(log_path)\n",
    "\n",
    "torch.set_printoptions(\n",
    "    precision=2,\n",
    "    threshold=1000,\n",
    "    edgeitems=5,\n",
    "    linewidth=1000,\n",
    "    sci_mode=False)\n",
    "# 是否使用显卡加速\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    log.info(f'device {device} is used.')\n",
    "    if torch.backends.cudnn.is_available():\n",
    "        torch.backends.cudnn.enabled = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        log.info('cudnn is actived.')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "    log.info(f'device {device} is used.')\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    log.info(f'device {device} is used.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--dataset DATASET] [--alpha ALPHA] [--T T]\n",
      "                             [--num_all_client NUM_ALL_CLIENT]\n",
      "                             [--num_all_server NUM_ALL_SERVER]\n",
      "                             [--batch_size BATCH_SIZE]\n",
      "                             [--num_client_data NUM_CLIENT_DATA]\n",
      "                             [--num_server_commu NUM_SERVER_COMMU]\n",
      "                             [--num_client_commu NUM_CLIENT_COMMU]\n",
      "                             [--num_client_train NUM_CLIENT_TRAIN]\n",
      "                             [--num_public_train NUM_PUBLIC_TRAIN]\n",
      "                             [--model_select MODEL_SELECT]\n",
      "                             [--algorithm ALGORITHM]\n",
      "                             [--num_public_data NUM_PUBLIC_DATA]\n",
      "                             [--proportion PROPORTION]\n",
      "                             [--server_client SERVER_CLIENT]\n",
      "                             [--neighbor_server NEIGHBOR_SERVER]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=/home/dhf/.local/share/jupyter/runtime/kernel-v2-27011zVt8X9ppJytr.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "# %% 参数定义\n",
    "\n",
    "args = get_args()\n",
    "args.device = device\n",
    "\n",
    "# comm = MPI.COMM_WORLD\n",
    "# rank = comm.Get_rank()\n",
    "# alpha = 0.5\n",
    "# T = 2\n",
    "# num_server_commu = 15\n",
    "# num_client_commu = 10\n",
    "# num_client_train = 10\n",
    "# num_public_train = 10\n",
    "# batch_size = 200\n",
    "# dataset = 'mnist'\n",
    "\n",
    "# num_all_client = 9\n",
    "# num_all_server = 3\n",
    "# num_client_data = 1000\n",
    "# num_public_data = 50\n",
    "# proportion = 0.8\n",
    "# server_client = [[0, 1, 2], [3, 4, 5], [6, 7, 8]]\n",
    "# neighbor_server = [[1], [2], [0]]\n",
    "all_client = [i for i in range(args.num_all_client)]\n",
    "all_server = [i for i in range(args.num_all_server)]\n",
    "num_server_client = args.num_all_client // args.num_all_server\n",
    "\n",
    "message = '\\n\\\n",
    "    {:^19}:{:^7}\\n\\\n",
    "    {:^19}:{:^7}\\n\\\n",
    "    {:^19}:{:^7}\\n\\\n",
    "    {:^19}:{:^7}\\n\\\n",
    "    {:^19}:{:^7}\\n\\\n",
    "    {:^19}:{:^7}\\n\\\n",
    "    {:^19}:{:^7}\\n\\\n",
    "    {:^19}:{:^7}\\n\\\n",
    "    {:^19}:{:^7}\\n\\\n",
    "    {:^19}:{:^7}\\n\\\n",
    "    {:^19}:{:^7}\\n\\\n",
    "    {:^19}:{:^7}\\n\\\n",
    "    {:^19}:{:^7}\\n\\\n",
    "    {:^19}:{:^7}\\n'.format(\n",
    "    'alpha', args.alpha,\n",
    "    'T', args.T,\n",
    "    'num_server_commu', args.num_server_commu,\n",
    "    'num_client_commu', args.num_client_commu,\n",
    "    'num_client_train', args.num_client_train,\n",
    "    'num_public_train', args.num_public_train,\n",
    "    'batch_size', args.batch_size,\n",
    "    'dataset', args.dataset,\n",
    "    'model_select', args.model_select,\n",
    "    'num_all_client', args.num_all_client,\n",
    "    'num_all_server', args.num_all_server,\n",
    "    'num_client_data', args.num_client_data,\n",
    "    'num_public_data', args.num_public_data,\n",
    "    'proportion', args.proportion)\n",
    "log.info(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 原始数据处理\n",
    "train_dataset_o, test_dataset_o, c, h, w = get_dataset(args.dataset)\n",
    "TrainDatasetSplited = SplitData(train_dataset_o)\n",
    "all_target = TrainDatasetSplited.targets\n",
    "num_target = TrainDatasetSplited.num_target\n",
    "\n",
    "client_main_target = numpy.random.choice(\n",
    "    all_target, args.num_all_client, replace=False).tolist()\n",
    "train_dataset_client = TrainDatasetSplited.server_non_iid(\n",
    "    num_server=args.num_all_server,\n",
    "    num_server_client=num_server_client,\n",
    "    num_client_data=args.num_client_data,\n",
    "    client_main_target=client_main_target,\n",
    "    proportion=args.proportion)\n",
    "train_dataloader = list_same_term(args.num_all_client)\n",
    "for i, dataset_ in enumerate(train_dataset_client):\n",
    "    train_dataloader[i] = DataLoader(\n",
    "        dataset=dataset_,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True)\n",
    "[public_dataset, test_dataset] = split_parts_random(\n",
    "    test_dataset_o, [args.num_public_data, int(len(test_dataset_o)) - args.num_public_data])\n",
    "public_dataloader = DataLoader(\n",
    "    dataset=public_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=True)\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 模型初始化\n",
    "if args.model_select == 1:\n",
    "    model = CNN(h, w, c, num_target)\n",
    "    client_model = list_same_term(args.num_all_client, model)\n",
    "elif args.model_select == 2:\n",
    "    model = LeNet5(h, w, c, num_target)\n",
    "    client_model = list_same_term(args.num_all_client, model)\n",
    "elif args.model_select == 3:\n",
    "    model1 = CNN(h, w, c, num_target)\n",
    "    model2 = LeNet5(h, w, c, num_target)\n",
    "    model3 = MLP(h, w, c, 50, num_target)\n",
    "    client_model = []\n",
    "else:\n",
    "    raise ValueError('model error.')\n",
    "\n",
    "\n",
    "server_model = deepcopy(client_model)\n",
    "server_accuracy = list_same_term(args.num_all_server)\n",
    "client_accuracy = list_same_term(args.num_all_client)\n",
    "server_client_model = deepcopy(server_accuracy)\n",
    "client_loss = deepcopy(client_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 模型训练\n",
    "keys = ['server_model', 'train_dataloader', 'test_dataloader',\n",
    "        'public_dataloader', 'log', 'client_model', 'num_target', 'neighbor', 'client_idx', 'client_accuracy', 'client_loss']\n",
    "values = [server_model, train_dataloader, test_dataloader,\n",
    "          public_dataloader, log, None, num_target, None, None, client_accuracy, client_loss]\n",
    "args_train = dict(zip(keys, values))\n",
    "\n",
    "client_model_save = dict.fromkeys([i for i in range(args.num_client_commu)])\n",
    "server_model_save = dict.fromkeys([i for i in range(args.num_server_commu)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 对每个服务器通讯幕进行循环\n",
    "for epoch_server_commu in range(args.num_server_commu):\n",
    "    log.info('-'*50)\n",
    "    log.info('|epoch_server_commu: {}/{}'.format(epoch_server_commu,\n",
    "             args.num_server_commu))\n",
    "    # 所有边缘服务器分别协调其客户端进行多轮联邦学习\n",
    "    for epoch_client_commu in range(args.num_client_commu):\n",
    "        message = ' |epoch_client_commu: {}/{}'.format(\n",
    "            epoch_client_commu, args.num_client_commu)\n",
    "        log.info(message)\n",
    "        # 所有边缘服务器分别协调其客户端进行联邦学习\n",
    "        neighbor_model = []\n",
    "        for server in all_server:\n",
    "            # 每个服务器下单客户端分别训练\n",
    "            message = f'  |server: {server}'\n",
    "            log.info(message)\n",
    "            args_train['client_idx'] = args.server_client[server]\n",
    "            args_train['client_model'] = client_model\n",
    "            if args.algorithm == 0:\n",
    "                if epoch_server_commu == 0:\n",
    "                    client_model = ServerTrain(args, args_train, 1).train\n",
    "                else:\n",
    "                    for i in args.neighbor_server[server]:\n",
    "                        neighbor_model.append(server_model[i])\n",
    "                    args_train['neighbor'] = neighbor_model\n",
    "                    client_model = ServerTrain(args, args_train, 3).train\n",
    "            if args.algorithm == 1:\n",
    "                if epoch_server_commu == 0:\n",
    "                    client_model = ServerTrain(args, args_train, 1).train\n",
    "                else:\n",
    "                    for i in args.neighbor_server[server]:\n",
    "                        neighbor_model.append(server_model[i])\n",
    "                    args_train['neighbor'] = neighbor_model\n",
    "                    client_model = ServerTrain(args, args_train, 4).train\n",
    "            if args.algorithm == 2 or args.algorithm == 3:\n",
    "                client_model = ServerTrain(args, args_train, 1).train\n",
    "            if args.algorithm == 4:\n",
    "                client_model = ServerTrain(args, args_train, 2).train\n",
    "            # 在单个服务器下客户端训练完成后更新该服务器下客户端的模型\n",
    "            server_client_model[server] = [\n",
    "                client_model[client] for client in args.server_client[server]]\n",
    "            # 聚合获得单个服务器模型并下发\n",
    "            weight_server = [1/2, 1/2]\n",
    "            server_model[server] = aggregate(\n",
    "                server_client_model[server], weight_server)\n",
    "            for client in args.server_client[server]:\n",
    "                client_model[client] = deepcopy(server_model[server])\n",
    "            # 评估单个服务器模型\n",
    "            acc_server = eval_model(\n",
    "                model=server_model[server],\n",
    "                dataloader=test_dataloader,\n",
    "                device=device)\n",
    "            message = '|servers comunicated: {}, server aggregated: {}, acc_server {}: {:.3f}.'.format(\n",
    "                epoch_server_commu, epoch_client_commu, server, acc_server)\n",
    "            log.info(message)\n",
    "            log.info('-'*50)\n",
    "            server_accuracy[server].append(acc_server)\n",
    "        if args.algorithm == 2:\n",
    "            weight_list = [[1/2, 1/2], [1/2, 1/2]]\n",
    "            server_model = server_communicate(server_model, weight_list)\n",
    "            for server in all_server:\n",
    "                for client in args.server_client[server]:\n",
    "                    client_model[client] = deepcopy(server_model[server])\n",
    "        client_model_save[epoch_client_commu] = client_model\n",
    "    server_model_save[epoch_client_commu] = server_model\n",
    "    message = '{:^50}'.format('********  servers comunicates  ********')\n",
    "    log.info(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data = {'args': args,\n",
    "             'server_model': server_model_save,\n",
    "             'server_acc': server_accuracy,\n",
    "             'client_model': client_model_save,\n",
    "             'client_acc': client_accuracy,\n",
    "             'client_loss': client_loss}\n",
    "save_file(args, save_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "federated_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
