{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from utils.model_util import LeNet5, CNN, MLP\n",
    "from utils.train_util import *\n",
    "\n",
    "model = LeNet5(28, 28, 1, 10).cuda()\n",
    "train_dataset_loader = DataLoader(\n",
    "    dataset=torchvision.datasets.MNIST(\n",
    "        root='../data/raw-data/',\n",
    "        train=True,\n",
    "        transform=torchvision.transforms.ToTensor()),\n",
    "    batch_size=600,\n",
    "    shuffle=False)\n",
    "test_dataset_loader = DataLoader(\n",
    "    dataset=torchvision.datasets.mnist.MNIST(\n",
    "        root='../data/raw-data/',\n",
    "        transform=torchvision.transforms.ToTensor()),\n",
    "    batch_size=32,\n",
    "    shuffle=False)\n",
    "test_dataset = torchvision.datasets.mnist.MNIST(\n",
    "    root='../data/raw-data/',\n",
    "    transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "opti = torch.optim.Adam(model.parameters())\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "for data, target in train_dataset_loader:\n",
    "    opti.zero_grad()\n",
    "    output = model(data.cuda())\n",
    "    loss = criterion(output, target.cuda())\n",
    "    loss.backward()\n",
    "    print(loss.item())\n",
    "    opti.step()\n",
    "\n",
    "print(loss, type(loss))\n",
    "print(loss.item(), type(loss.item()))\n",
    "\n",
    "model = LeNet5(28, 28, 1, 10).cuda()\n",
    "train_dataset_loader = DataLoader(\n",
    "    dataset=torchvision.datasets.MNIST(\n",
    "        root='../data/raw-data/',\n",
    "        train=True,\n",
    "        transform=torchvision.transforms.ToTensor()),\n",
    "    batch_size=600,\n",
    "    shuffle=False)\n",
    "test_dataset_loader = DataLoader(\n",
    "    dataset=torchvision.datasets.mnist.MNIST(\n",
    "        root='../data/raw-data/',\n",
    "        transform=torchvision.transforms.ToTensor()),\n",
    "    batch_size=32,\n",
    "    shuffle=False)\n",
    "\n",
    "opti = torch.optim.Adam(model.parameters())\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "loss_sum = 0\n",
    "for data, target in train_dataset_loader:\n",
    "    opti.zero_grad()\n",
    "    output = model(data.cuda())\n",
    "    loss = criterion(output, target.cuda())\n",
    "    # print(f'loss_sum = {loss_sum:<20}', end=' | ')\n",
    "    loss.backward()\n",
    "    loss_sum += loss.item()\n",
    "    # print(f'loss = {loss.item():<20}')\n",
    "    opti.step()\n",
    "\n",
    "def eval_model(model, dataset, device):\n",
    "    '''\n",
    "    评估模型\n",
    "    '''\n",
    "    model_copy = deepcopy(model).eval()\n",
    "    correct = 0\n",
    "    data_loader = DataLoader(dataset, batch_size=32)\n",
    "    for images, targets in data_loader:\n",
    "        outputs = model_copy(images.to(device))\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += torch.eq(predicted, targets.to(device)).sum()\n",
    "    # print(f'Test Accuracy: {100 * correct / total:.2f}%')\n",
    "    accuracy = correct / len(dataset)\n",
    "    return accuracy\n",
    "\n",
    "eval_model(model, test_dataset, 'cuda')\n",
    "\n",
    "model_copy = deepcopy(model).eval()\n",
    "model_copy.eval()\n",
    "model_copy.cuda()\n",
    "correct = 0\n",
    "total = 0\n",
    "data_loader = test_dataset_loader\n",
    "for images, targets in data_loader:\n",
    "    outputs = model_copy(images.cuda())\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += targets.size(0)\n",
    "    correct += (predicted == targets.cuda()).sum().item()\n",
    "    break\n",
    "print('Test Accuracy: {:.2f}%'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8, 13):\n",
    "    print(f'{i:<10}|')\n",
    "    print(f'{i:.2f}|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list(len_list, term=[]):\n",
    "    '''\n",
    "    返回一个全是空列表的列表\n",
    "    '''\n",
    "    list_return = []\n",
    "    for _ in range(len_list):\n",
    "        list_return.append(term)\n",
    "    return list_return\n",
    "\n",
    "num_all_client = 6\n",
    "num_all_server = 2\n",
    "\n",
    "server_model = get_list(num_all_server)\n",
    "server_accuracy = get_list(num_all_server)\n",
    "client_accuracy = get_list(num_all_client)\n",
    "server_client_model = get_list(num_all_server)\n",
    "server_model_distillation_accuracy = get_list(num_all_server)\n",
    "\n",
    "print(client_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Files already downloaded and verified\n",
      "mode 1:  tensor(0.5055)\n",
      "mode 2:  tensor(0.5276)\n",
      "mode 3 before distill:  tensor(0.5098)\n",
      "mode 3 after distill:  tensor(0.4948)\n",
      "mode 3 train only in public dataset:  tensor(0.5104)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.data_util import *\n",
    "from utils.train_util import *\n",
    "from utils.model_util import *\n",
    "from utils.lib_util import *\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(device)\n",
    "\n",
    "save_path = '../data/dealed-data/'\n",
    "train_dataset_o, test_dataset_o = get_dataset(dataset='cifar10')\n",
    "train_dataset_splited = split_data(train_dataset_o)\n",
    "idx_client_target = train_data_split(train_dataset_splited, range(3))\n",
    "all_target = train_dataset_splited.keys()\n",
    "\n",
    "train_dataset_client = list_same_term(3)\n",
    "for client in range(3):\n",
    "    for target in all_target:\n",
    "        train_dataset_client_new = [train_dataset_splited[target][idx]\n",
    "                                    for idx in idx_client_target[client][target]]\n",
    "        train_dataset_client[client].extend(train_dataset_client_new)\n",
    "\n",
    "public_idx, test_idx = split_idx_proportion(\n",
    "    number_list(len(test_dataset_o)), [0.2, 0.8])\n",
    "public_dataset = DealDataset(test_dataset_o, public_idx)\n",
    "test_dataset = DealDataset(test_dataset_o, test_idx)\n",
    "\n",
    "model = CNN(32, 32, 3, 10)\n",
    "trained_model1, _ = train_model(\n",
    "    model=model,\n",
    "    dataset=train_dataset_client[0],\n",
    "    device=device,\n",
    "    epochs=10)\n",
    "print('mode 1: ', eval_model(trained_model1, test_dataset, device))\n",
    "trained_model2, _ = train_model(\n",
    "    model=model,\n",
    "    dataset=train_dataset_client[1],\n",
    "    device=device,\n",
    "    epochs=10)\n",
    "print('mode 2: ', eval_model(trained_model2, test_dataset, device))\n",
    "\n",
    "trained_model3, _ = train_model(\n",
    "    model=model,\n",
    "    dataset=train_dataset_client[2],\n",
    "    device=device,\n",
    "    epochs=10)\n",
    "print('mode 3 before distill: ', eval_model(trained_model3, test_dataset, device))\n",
    "\n",
    "trained_model4, _ = train_model(\n",
    "    model=trained_model3,\n",
    "    dataset=public_dataset,\n",
    "    device=device,\n",
    "    epochs=10)\n",
    "print('mode 3 after distill: ', eval_model(trained_model4, test_dataset, device))\n",
    "\n",
    "trained_model5, _ = train_model_disti(\n",
    "    model=trained_model3,\n",
    "    neighbor_server_model=[trained_model1, trained_model2],\n",
    "    weight=torch.tensor([0.5, 0.5]),\n",
    "    dataset=public_dataset,\n",
    "    alpha=0.5,\n",
    "    device=device,\n",
    "    epochs=10)\n",
    "print('mode 3 train only in public dataset: ', eval_model(trained_model5, test_dataset, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Files already downloaded and verified\n",
      "<class 'list'> 50000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.data_util import *\n",
    "from utils.train_util import *\n",
    "from utils.model_util import *\n",
    "from utils.lib_util import *\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(device)\n",
    "\n",
    "save_path = '../data/dealed-data/'\n",
    "train_dataset_o, test_dataset_o = get_dataset(dataset='cifar100')\n",
    "print(type(train_dataset_o.targets), len(train_dataset_o.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.data_util import *\n",
    "from utils.train_util import *\n",
    "from utils.model_util import *\n",
    "from utils.lib_util import *\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(device)\n",
    "\n",
    "save_path = '../data/dealed-data/'\n",
    "train_dataset_o, test_dataset_o = get_dataset()\n",
    "print(type(train_dataset_o.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3208, 0.4769, 0.0082, 0.7106],\n",
      "        [0.9084, 0.5454, 0.7445, 0.4033],\n",
      "        [0.0428, 0.1435, 0.5771, 0.0324]], device='cuda:0')\n",
      "tensor([0.3208, 0.4769, 0.0082, 0.7106], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand(3, 4)\n",
    "b = a.to('cuda')\n",
    "\n",
    "print(b)\n",
    "print(b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[100, 101, 102, 103, 104, 105, 106, 107, 108, 109]\n",
      "{'a': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 'b': [100, 101, 102, 103, 104, 105, 106, 107, 108, 109]}\n",
      "[2, 6, 4, 1, 0, 8, 7, 9, 3, 5]\n"
     ]
    }
   ],
   "source": [
    "import random, copy\n",
    "\n",
    "a = [i for i in range(10)]\n",
    "b = [i+100 for i in range(10)]\n",
    "c = {'a': a, 'b': b}\n",
    "\n",
    "d = copy.deepcopy(c['a'])\n",
    "random.shuffle(d)\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [1, 2] [1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "a = [i for i in range(10)]\n",
    "b = a[1:3]\n",
    "c = a[1:]\n",
    "print(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 8, 5] <class 'list'>\n",
      "0\n",
      "8 <class 'int'>\n",
      "1\n",
      "8 <class 'int'>\n",
      "2\n",
      "5 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "a = [i for i in range(10)]\n",
    "b = numpy.random.choice(a, 3, replace=True).tolist()\n",
    "print(b, type(b))\n",
    "\n",
    "for i, c in enumerate(b):\n",
    "    print(i)\n",
    "    print(c, type(c))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
